================================================================================================================================
ContraTCR Colab Test
================================================================================================================================
Executed with: python ./run.py--config_path./config/final/final_clean_adapter_16.yaml--train_feature_path./result/final_clean_extract/20241128-05-56-55/feature_data_train.csv--test_feature_path./result/final_clean_extract/20241128-05-56-55/feature_data_test.csv--modepredict--result_path./result/final_clean_predict/
================================================================================================================================
Result Directory: /mnt/pixstor/data/yz3qt/11785-TCR/result/final_clean_predict/20241130-23-38-59
Checkpoint Directory: /mnt/pixstor/data/yz3qt/11785-TCR/result/final_clean_predict/20241130-23-38-59/checkpoint
Log Directory: /mnt/pixstor/data/yz3qt/11785-TCR/result/final_clean_predict/20241130-23-38-59/loginfo.log
Config Directory: /mnt/pixstor/data/yz3qt/11785-TCR/result/final_clean_predict/20241130-23-38-59/final_clean_adapter_16.yaml
Current Working Directory: /mnt/pixstor/data/yz3qt/11785-TCR
================================================================================================================================
#### final_clean_adapter_16.yaml ####
    #fix_seed: 42
    description: "ContraTCR Colab Test"
    dataset: "PyTDC"
    tcr_embedding_source: "BindingSite"
              # "Full"
    batch_mode: "ByEpitope"
                  # "ByEpitope"
                  # "Regular"
    batch_size: 192  # 192
    epochs: 34400  # 86 * 400
    max_learning_rate: 3e-4
    min_learning_rate: 0
    
    optimizer_beta1: 0.9
    optimizer_beta2: 0.999
    optimizer_weight_decay: 0.0005
    optimizer_eps: 1e-16
    
    scheduler_first_cycle_steps: 100
    scheduler_warmup_epochs: 0
    scheduler_gamma: 1
    
    contrastive_mode: "Triplet"
                      # "Triplet"
                      # "MultiPosNeg"
    n_pos: 2
    n_neg: 3
    temp: 0.1
    
    negative_sampling_mode: "ExcludePos"
                            # "ExcludePos"
                            # "RandomNeg"
                            # "HardNeg"
    hard_neg_mining_sample_num: 1
    hard_neg_mining_adaptive_rate: 2
    
    encoder_name:  esm2_t33_650M_UR50D
                    # esm2_t36_3B_UR50D,
                    # esm2_t33_650M_UR50D,
                    # esm2_t30_150M_UR50D,
                    # esm2_t12_35M_UR50D,
                    # esm2_t6_8M_UR50D,
    tune_ESM_table: False
    fine_tuning:
      enable: False
      unfix_last_layer: 4
    adapter_h:
      enable: True
      num_end_adapter_layers: 16
      module_type: "MLP1"
    lora:
      enable: False
      esm_num_end_lora: -1
      r: 8
      alpha: 32
      dropout: 0.05
    
    
    projection_head_name: "LayerNorm"
    hidden_dim: 512
    out_dim: 128
    drop_out: 0.1
================================================================================================================================
XGBoost model training & binding specificity prediction
Accuracy on test data: 0.7164
AUROC on test data: 0.7823
AUPR on test data: 0.7610
F1 Score on test data: 0.7134
Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.73      0.72      2335
           1       0.73      0.70      0.71      2383

    accuracy                           0.72      4718
   macro avg       0.72      0.72      0.72      4718
weighted avg       0.72      0.72      0.72      4718

================================================================================================================================
XGBoost model training & binding specificity prediction - with additional SMI features
Accuracy on test data: 0.7232
AUROC on test data: 0.7846
AUPR on test data: 0.7630
F1 Score on test data: 0.7218
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.74      0.72      2335
           1       0.73      0.71      0.72      2383

    accuracy                           0.72      4718
   macro avg       0.72      0.72      0.72      4718
weighted avg       0.72      0.72      0.72      4718

================================================================================================================================
MLP model training & binding specificity prediction
Accuracy on test data: 0.7238
AUROC on test data: 0.7857
AUPR on test data: 0.7656
F1 Score on test data: 0.7317
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.70      0.72      2335
           1       0.72      0.75      0.73      2383

    accuracy                           0.72      4718
   macro avg       0.72      0.72      0.72      4718
weighted avg       0.72      0.72      0.72      4718

================================================================================================================================
MLP model training & binding specificity prediction - with additional SMI features
Accuracy on test data: 0.7274
AUROC on test data: 0.7843
AUPR on test data: 0.7591
F1 Score on test data: 0.7325
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.72      0.72      2335
           1       0.73      0.74      0.73      2383

    accuracy                           0.73      4718
   macro avg       0.73      0.73      0.73      4718
weighted avg       0.73      0.73      0.73      4718

================================================================================================================================
CNN model training & binding specificity prediction
Accuracy on test data: 0.7170
AUROC on test data: 0.7807
AUPR on test data: 0.7602
F1 Score on test data: 0.7014
Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.78      0.73      2335
           1       0.75      0.66      0.70      2383

    accuracy                           0.72      4718
   macro avg       0.72      0.72      0.72      4718
weighted avg       0.72      0.72      0.72      4718

================================================================================================================================
CNN model training & binding specificity prediction - with additional SMI features
Accuracy on test data: 0.7283
AUROC on test data: 0.7895
AUPR on test data: 0.7690
F1 Score on test data: 0.7265
Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.74      0.73      2335
           1       0.74      0.71      0.73      2383

    accuracy                           0.73      4718
   macro avg       0.73      0.73      0.73      4718
weighted avg       0.73      0.73      0.73      4718

