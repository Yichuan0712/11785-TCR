================================================================================================================================
ContraTCR Colab Test
================================================================================================================================
Executed with: python ./run.py--config_path./config/final/final_regular_lora_16.yaml--train_feature_path./result/final_regular_extract/20241128-05-35-47/feature_data_train.csv--test_feature_path./result/final_regular_extract/20241128-05-35-47/feature_data_test.csv--modepredict--result_path./result/final_regular_predict/
================================================================================================================================
Result Directory: /mnt/pixstor/data/yz3qt/11785-TCR/result/final_regular_predict/20241201-02-26-05
Checkpoint Directory: /mnt/pixstor/data/yz3qt/11785-TCR/result/final_regular_predict/20241201-02-26-05/checkpoint
Log Directory: /mnt/pixstor/data/yz3qt/11785-TCR/result/final_regular_predict/20241201-02-26-05/loginfo.log
Config Directory: /mnt/pixstor/data/yz3qt/11785-TCR/result/final_regular_predict/20241201-02-26-05/final_regular_lora_16.yaml
Current Working Directory: /mnt/pixstor/data/yz3qt/11785-TCR
================================================================================================================================
#### final_regular_lora_16.yaml ####
    #fix_seed: 42
    description: "ContraTCR Colab Test"
    dataset: "PyTDC"
    tcr_embedding_source: "BindingSite"
              # "Full"
    batch_mode: "Regular"
                  # "ByEpitope"
                  # "Regular"
    batch_size: 192  # 192
    epochs: 400
    max_learning_rate: 3e-4
    min_learning_rate: 0
    
    optimizer_beta1: 0.9
    optimizer_beta2: 0.999
    optimizer_weight_decay: 0.0005
    optimizer_eps: 1e-16
    
    scheduler_first_cycle_steps: 100
    scheduler_warmup_epochs: 0
    scheduler_gamma: 1
    
    contrastive_mode: "Triplet"
                      # "Triplet"
                      # "MultiPosNeg"
    n_pos: 2
    n_neg: 3
    temp: 0.1
    
    negative_sampling_mode: "ExcludePos"
                            # "ExcludePos"
                            # "RandomNeg"
                            # "HardNeg"
    hard_neg_mining_sample_num: 1
    hard_neg_mining_adaptive_rate: 2
    
    encoder_name:  esm2_t33_650M_UR50D
                    # esm2_t36_3B_UR50D,
                    # esm2_t33_650M_UR50D,
                    # esm2_t30_150M_UR50D,
                    # esm2_t12_35M_UR50D,
                    # esm2_t6_8M_UR50D,
    tune_ESM_table: False
    fine_tuning:
      enable: False
      unfix_last_layer: 4
    adapter_h:
      enable: False
      num_end_adapter_layers: 12
      module_type: "MLP1"
    lora:
      enable: True
      esm_num_end_lora: 16
      r: 8
      alpha: 32
      dropout: 0.05
    
    
    projection_head_name: "LayerNorm"
    hidden_dim: 512
    out_dim: 128
    drop_out: 0.1
================================================================================================================================
XGBoost model training & binding specificity prediction
Accuracy on test data: 0.7041
AUROC on test data: 0.7820
AUPR on test data: 0.7769
F1 Score on test data: 0.7122
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.70      2335
           1       0.70      0.72      0.71      2383

    accuracy                           0.70      4718
   macro avg       0.70      0.70      0.70      4718
weighted avg       0.70      0.70      0.70      4718

================================================================================================================================
XGBoost model training & binding specificity prediction - with additional SMI features
Accuracy on test data: 0.7257
AUROC on test data: 0.7985
AUPR on test data: 0.7864
F1 Score on test data: 0.7280
Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.72      0.72      2335
           1       0.73      0.73      0.73      2383

    accuracy                           0.73      4718
   macro avg       0.73      0.73      0.73      4718
weighted avg       0.73      0.73      0.73      4718

================================================================================================================================
MLP model training & binding specificity prediction
Accuracy on test data: 0.7293
AUROC on test data: 0.8016
AUPR on test data: 0.7848
F1 Score on test data: 0.7313
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.73      0.73      2335
           1       0.73      0.73      0.73      2383

    accuracy                           0.73      4718
   macro avg       0.73      0.73      0.73      4718
weighted avg       0.73      0.73      0.73      4718

================================================================================================================================
MLP model training & binding specificity prediction - with additional SMI features
Accuracy on test data: 0.7340
AUROC on test data: 0.8064
AUPR on test data: 0.7927
F1 Score on test data: 0.7341
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.74      0.73      2335
           1       0.74      0.73      0.73      2383

    accuracy                           0.73      4718
   macro avg       0.73      0.73      0.73      4718
weighted avg       0.73      0.73      0.73      4718

================================================================================================================================
CNN model training & binding specificity prediction
Accuracy on test data: 0.7321
AUROC on test data: 0.8065
AUPR on test data: 0.7959
F1 Score on test data: 0.7348
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.73      0.73      2335
           1       0.73      0.73      0.73      2383

    accuracy                           0.73      4718
   macro avg       0.73      0.73      0.73      4718
weighted avg       0.73      0.73      0.73      4718

================================================================================================================================
CNN model training & binding specificity prediction - with additional SMI features
Accuracy on test data: 0.7344
AUROC on test data: 0.8099
AUPR on test data: 0.7944
F1 Score on test data: 0.7431
Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.71      0.73      2335
           1       0.73      0.76      0.74      2383

    accuracy                           0.73      4718
   macro avg       0.73      0.73      0.73      4718
weighted avg       0.73      0.73      0.73      4718

