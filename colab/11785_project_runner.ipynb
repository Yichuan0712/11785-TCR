{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moHsEGjQ0Wsq",
        "outputId": "3ade7e6f-ee4c-4caf-ee94-dae0b2995656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '11785-TCR'...\n",
            "remote: Enumerating objects: 155, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 155 (delta 64), reused 119 (delta 31), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (155/155), 1.23 MiB | 5.41 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Yichuan0712/11785-TCR.git\n",
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir('11785-TCR')\n",
        "# os.listdir(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n",
        "!pip install 'git+https://github.com/facebookresearch/esm.git'\n",
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G27xzJtQqos4",
        "outputId": "260c4f00-6d7a-4450-d98b-68dd0110358f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup\n",
            "  Cloning https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup to /tmp/pip-req-build-fzpe6yh4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup /tmp/pip-req-build-fzpe6yh4\n",
            "  Resolved https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup to commit 12d03c07553aedd3d9e9155e2b3e31ce8c64081a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: cosine_annealing_warmup\n",
            "  Building wheel for cosine_annealing_warmup (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cosine_annealing_warmup: filename=cosine_annealing_warmup-2.0-py3-none-any.whl size=4169 sha256=33df187a04c9e95f651aa03f1ff5c9d457a03442a0240f42e0f9c102248638ba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y6g9v9u_/wheels/29/26/10/bf1a07417dd54aa73bdf09ce4f31c187974a444a1cedddbd99\n",
            "Successfully built cosine_annealing_warmup\n",
            "Installing collected packages: cosine_annealing_warmup\n",
            "Successfully installed cosine_annealing_warmup-2.0\n",
            "Collecting git+https://github.com/facebookresearch/esm.git\n",
            "  Cloning https://github.com/facebookresearch/esm.git to /tmp/pip-req-build-li4lnipr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/esm.git /tmp/pip-req-build-li4lnipr\n",
            "  Resolved https://github.com/facebookresearch/esm.git to commit 2b369911bb5b4b0dda914521b9475cad1656b2ac\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fair-esm\n",
            "  Building wheel for fair-esm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fair-esm: filename=fair_esm-2.0.1-py3-none-any.whl size=105380 sha256=c4dc927be49ce1f8056a66c9b58a091c2d50edb3cbf909d8a1cf2367ab8a116b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pgbv0j19/wheels/f3/b2/ec/4db0b108f6367c7563f99b2445e1137d486003fb2f9bfd2f53\n",
            "Successfully built fair-esm\n",
            "Installing collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.1\n",
            "Collecting peft\n",
            "  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Downloading peft-0.13.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: peft\n",
            "Successfully installed peft-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQLr-P1Y0fJJ",
        "outputId": "07842d44-7433-4cbb-9d58-1487d7955f52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/Yichuan0712/11785-TCR\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcSfllJR0jT2",
        "outputId": "c38865e3-ddaa-4f22-af8f-97fadc54354e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================================================================\n",
            "               ______   ______   .__   __. .___________..______          ___   .___________.  ______ .______      \n",
            "              /      | /  __  \\  |  \\ |  | |           ||   _  \\        /   \\  |           | /      ||   _  \\     \n",
            "             |  ,----'|  |  |  | |   \\|  | `---|  |----`|  |_)  |      /  ^  \\ `---|  |----`|  ,----'|  |_)  |    \n",
            "             |  |     |  |  |  | |  . `  |     |  |     |      /      /  /_\\  \\    |  |     |  |     |      /     \n",
            "             |  `----.|  `--'  | |  |\\   |     |  |     |  |\\  \\----./  _____  \\   |  |     |  `----.|  |\\  \\----.\n",
            "              \\______| \\______/  |__| \\__|     |__|     | _| `._____/__/     \\__\\  |__|      \\______|| _| `._____|\n",
            "\n",
            "================================================================================================================================\n",
            "ContraTCR Colab Test\n",
            "================================================================================================================================\n",
            "Executed with: python run.py\n",
            "================================================================================================================================\n",
            "Result Directory: /content/11785-TCR/result/default/20241004-04-50-00\n",
            "Checkpoint Directory: /content/11785-TCR/result/default/20241004-04-50-00/checkpoint\n",
            "Log Directory: /content/11785-TCR/result/default/20241004-04-50-00/loginfo.log\n",
            "Config Directory: /content/11785-TCR/result/default/20241004-04-50-00/config.yaml\n",
            "Current Working Directory: /content/11785-TCR\n",
            "================================================================================================================================\n",
            "#### config.yaml ####\n",
            "    fix_seed: 42\n",
            "    description: \"ContraTCR Colab Test\"\n",
            "    dataset: \"pytdc\"\n",
            "    batch_size: 16\n",
            "    \n",
            "    encoder_name:  esm2_t6_8M_UR50D\n",
            "                  # esm2_t36_3B_UR50D,\n",
            "                  # esm2_t33_650M_UR50D,\n",
            "                  # esm2_t30_150M_UR50D,\n",
            "                  # esm2_t12_35M_UR50D,\n",
            "                  # esm2_t6_8M_UR50D,\n",
            "    tune_ESM_table: False\n",
            "    fine_tuning:\n",
            "      enable: True\n",
            "      unfix_last_layer: 4\n",
            "    adapter_h:\n",
            "      enable: False\n",
            "      num_end_adapter_layers: 12\n",
            "      module_type: \"MLP1\"\n",
            "    lora:\n",
            "      enable: False\n",
            "      esm_num_end_lora: -1\n",
            "      r: 8\n",
            "      alpha: 32\n",
            "      dropout: 0.05\n",
            "    \n",
            "================================================================================================================================\n",
            "Random seed set to 42.\n",
            "================================================================================================================================\n",
            "Number of Steps for Training Data: 1033\n",
            "Number of Steps for Validation Data: 149\n",
            "Number of Steps for Test Data: 293\n",
            "Data loading complete.\n",
            "================================================================================================================================\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t6_8M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D-contact-regression.pt\n",
            "Model initialization complete.\n"
          ]
        }
      ]
    }
  ]
}